{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "977deac2",
   "metadata": {},
   "source": [
    "# 1. Integer Encoding & Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e5a611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_raw_text = \"\"\"\n",
    "A barber is a person. a barber is good person. a barber is huge person. \n",
    "he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. \n",
    "a barber kept his word. His barber kept his secret. \n",
    "But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1981ee10",
   "metadata": {},
   "source": [
    "- <span style = 'font-size:1.2em;line-height:1.5em'>먼저, 다음과 같은 전처리들을 수행합니다.</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'>(1) 대문자 --> 소문자</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'>(2) 불용어, 길이가 2이하인 단어 제거</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a04cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20dacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 줄바꿈 문자(\\n) 제거 (Remove new line char)\n",
    "trn_raw_text = trn_raw_text.replace('\\n', ' ')\n",
    "\n",
    "# stopwords set 생성 (Make stopword set)\n",
    "stopwords_eng = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f957e509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A barber is a person. a barber is good person. a barber is huge person.  he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word.  a barber kept his word. His barber kept his secret.  But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain. '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1045a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 토큰화 (sentence tokenization)\n",
    "sentences = sent_tokenize(trn_raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb83d88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' A barber is a person.',\n",
       " 'a barber is good person.',\n",
       " 'a barber is huge person.',\n",
       " 'he Knew A Secret!',\n",
       " 'The Secret He Kept is huge secret.',\n",
       " 'Huge secret.',\n",
       " 'His barber kept his word.',\n",
       " 'a barber kept his word.',\n",
       " 'His barber kept his secret.',\n",
       " 'But keeping and keeping such a huge secret to himself was driving the barber crazy.',\n",
       " 'the barber went up a huge mountain.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4307c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "for sentence in sentences: # 각 문장에 대해서\n",
    "    sentence = sentence.lower()\n",
    "    words = word_tokenize(sentence)\n",
    "    sent_tokens = []\n",
    "    for word in words:\n",
    "        if (word not in stopwords_eng) & (len(word)>2):\n",
    "            sent_tokens.append(word)\n",
    "    all_tokens.append(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d94f2433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['barber', 'person'],\n",
       " ['barber', 'good', 'person'],\n",
       " ['barber', 'huge', 'person'],\n",
       " ['knew', 'secret'],\n",
       " ['secret', 'kept', 'huge', 'secret'],\n",
       " ['huge', 'secret'],\n",
       " ['barber', 'kept', 'word'],\n",
       " ['barber', 'kept', 'word'],\n",
       " ['barber', 'kept', 'secret'],\n",
       " ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
       " ['barber', 'went', 'huge', 'mountain']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44523b0c",
   "metadata": {},
   "source": [
    "## (1) vocabulary set 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcbd9fa",
   "metadata": {},
   "source": [
    "### Method 1. Counter 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d6a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34aaaa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for sent_tokens in all_tokens:\n",
    "    all_words.extend(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "749e5751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
     ]
    }
   ],
   "source": [
    "cnt = Counter(all_words)\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b8d7186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n"
     ]
    }
   ],
   "source": [
    "# 빈도수가 상위 5위안에 속하는 단어 사전 만들기\n",
    "# Create a word dictionary with the top 5 frequencies\n",
    "vocab = cnt.most_common(5)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9489c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 기준 정렬 전:  [('barber', 8), ('person', 3), ('huge', 5), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2)]\n",
      "빈도수 기준 정렬 후:  [('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2)]\n"
     ]
    }
   ],
   "source": [
    "# 빈도수가 2번 이상 등장한 단어 사전 만들기\n",
    "# Generate a word dictionary with words that occurs more than 2 times\n",
    "vocab = [(k,v) for (k,v) in zip(cnt.keys(), cnt.values()) if v>=2]\n",
    "print(\"빈도수 기준 정렬 전: \", vocab)\n",
    "vocab = sorted(vocab, key = lambda x: x[1], reverse=True)\n",
    "print(\"빈도수 기준 정렬 후: \", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61864109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 0, 'secret': 1, 'huge': 2, 'kept': 3, 'person': 4, 'word': 5, 'keeping': 6}\n"
     ]
    }
   ],
   "source": [
    "# {단어: index}형태의 dictionary 만들기\n",
    "# Generate a dictionary with {word: index}\n",
    "word_dict = dict()\n",
    "for i, (word, freq) in enumerate(vocab):\n",
    "    word_dict[word] = i\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caf0546",
   "metadata": {},
   "source": [
    "### Method 2: nltk 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63244c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1245dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae46b8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, ...})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cd623a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]\n"
     ]
    }
   ],
   "source": [
    "# 빈도수가 상위 5위안에 속하는 단어 사전 만들기\n",
    "# Create a word dictionary with the top 5 frequencies\n",
    "vocab = cnt.most_common(5)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba70cb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 기준 정렬 전:  [('barber', 8), ('person', 3), ('huge', 5), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2)]\n",
      "빈도수 기준 정렬 후:  [('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2)]\n"
     ]
    }
   ],
   "source": [
    "# 빈도수가 2번 이상 등장한 단어 사전 만들기\n",
    "# Generate a word dictionary with words that occurs more than 2 times\n",
    "vocab = [(k,v) for (k,v) in zip(cnt.keys(), cnt.values()) if v>=2]\n",
    "print(\"빈도수 기준 정렬 전: \", vocab)\n",
    "vocab = sorted(vocab, key = lambda x: x[1], reverse=True)\n",
    "print(\"빈도수 기준 정렬 후: \", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f478f4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 0, 'secret': 1, 'huge': 2, 'kept': 3, 'person': 4, 'word': 5, 'keeping': 6}\n"
     ]
    }
   ],
   "source": [
    "# {단어: index}형태의 dictionary 만들기\n",
    "# Generate a dictionary with {word: index}\n",
    "word_dict = dict()\n",
    "for i, (word, freq) in enumerate(vocab):\n",
    "    word_dict[word] = i\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee6375",
   "metadata": {},
   "source": [
    "#### Vocabulary set을 만들어 줄 때, 다음과 같은 추가 key, value를 입력해줘야 합니다.\n",
    "\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'><b>\\<Pad\\>: 0</b></span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'>문장의 길이를 맞춰줄때 필요합니다.</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'>일반적인 text mining할 때는 필요 없지만, Neural Network, 특히 RNN계열의 모델을 사용할 때 필요합니다.</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'>이렇게 길이를 맞춰주면 어느정도 병렬 처리가 가능하는 장점이 있습니다.</span>\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'><b>OOV: 1</b></span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'>OOV는 Out-of-Vocabulary를 의미합니다. Vocabulary에 등록되지 않은 단어들을 OOV로 일괄처리 합니다.</span>\n",
    "    - <span style = 'font-size:1.1em;line-height:1.5em'>앞의 예제에서 went, mountain과 같은 단어들은 단어 사전에 빠져있는데, 이들을 OOV로 일괄처리 합니다.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "582a595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word_dict = dict()\n",
    "new_word_dict['<PAD>'] = 0\n",
    "new_word_dict['OOV'] = 1\n",
    "for k, v in word_dict.items():\n",
    "    new_word_dict[k] = v+2\n",
    "\n",
    "del word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71acb2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " 'OOV': 1,\n",
       " 'barber': 2,\n",
       " 'secret': 3,\n",
       " 'huge': 4,\n",
       " 'kept': 5,\n",
       " 'person': 6,\n",
       " 'word': 7,\n",
       " 'keeping': 8}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d586df31",
   "metadata": {},
   "source": [
    "## (2) Integer Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dca6d5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['barber', 'person'],\n",
       " ['barber', 'good', 'person'],\n",
       " ['barber', 'huge', 'person'],\n",
       " ['knew', 'secret'],\n",
       " ['secret', 'kept', 'huge', 'secret'],\n",
       " ['huge', 'secret'],\n",
       " ['barber', 'kept', 'word'],\n",
       " ['barber', 'kept', 'word'],\n",
       " ['barber', 'kept', 'secret'],\n",
       " ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
       " ['barber', 'went', 'huge', 'mountain']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c542f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_enc = [] # 모든 문장들을 정수 인코딩된 형태로 변환시킬 리스트 생성\n",
    "for sent in all_tokens: # 각 문장(token sequence)에 대해서,\n",
    "    sent_tokens_enc = [] # 각 문장을 정수 인코딩된 형태로 변환시킬 리스트 생성 \n",
    "    for word in sent: # 문장의 각 단어(토큰)들에 대해서,\n",
    "        if word in new_word_dict.keys(): # 해당 단어가 word_dict의 key에 포함되어 있으면,\n",
    "            sent_tokens_enc.append(new_word_dict[word]) # 그에 해당하는 value로 정수 인코딩 \n",
    "        else: # 해당 단어가 word_dict의 key에 없으면\n",
    "            sent_tokens_enc.append(new_word_dict['OOV']) # OOV에 해당하는 value(1)로 정수 인코딩\n",
    "    all_tokens_enc.append(sent_tokens_enc) # 인코딩된 문장을 최종 결과에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e27cdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 6],\n",
       " [2, 1, 6],\n",
       " [2, 4, 6],\n",
       " [1, 3],\n",
       " [3, 5, 4, 3],\n",
       " [4, 3],\n",
       " [2, 5, 7],\n",
       " [2, 5, 7],\n",
       " [2, 5, 3],\n",
       " [8, 8, 4, 3, 1, 2, 1],\n",
       " [2, 1, 4, 1]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e630e2",
   "metadata": {},
   "source": [
    "## (3) Padding\n",
    "\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>패딩은 항상 사용하는게 아니고, 기계 번역처럼 neural network 계열의 모델링시, 특히 RNN계열의 모델을 활용할 때 필요하다고 생각하셔도 됩니다.</span>\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>즉, 필요할 때가 있고, 필요하지 않을 때가 있는데 이를 잘 구분하셔야 합니다.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db373e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 문장(token sequence)의 길이가 있는 리스트를 생성하고 tmp = ([len(x) for x in all_tokens_enc])\n",
    "# 그 리스트의 최대값을 구함 (max(tmp))\n",
    "max_len = max([len(x) for x in all_tokens_enc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "502062c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b671b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_enc_pad = [] ## 패딩 처리한 결과를 저장할 리스트 생성\n",
    "for sent_tokens_enc in all_tokens_enc: # 정수 인코딩된 각 문장에 대해서,\n",
    "    if len(sent_tokens_enc) <  max_len: # 해당 문장의 길이가 최대 문장 길이보다 작으면\n",
    "        num_pad = (max_len - len(sent_tokens_enc)) # 패딩 처리할 길이 = (최대 문장 길이 - 해당 문장 길이)\n",
    "        sent_tokens_enc += [0]*num_pad # 정수 인코딩된 각 문장에 0을 추가 (패딩 처리할 길이 만큼!)\n",
    "    all_tokens_enc_pad.append(sent_tokens_enc) # 패딩 처리한 문장 결과를 최종 결과에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5a7b10b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 6, 0, 0, 0, 0, 0],\n",
       " [2, 1, 6, 0, 0, 0, 0],\n",
       " [2, 4, 6, 0, 0, 0, 0],\n",
       " [1, 3, 0, 0, 0, 0, 0],\n",
       " [3, 5, 4, 3, 0, 0, 0],\n",
       " [4, 3, 0, 0, 0, 0, 0],\n",
       " [2, 5, 7, 0, 0, 0, 0],\n",
       " [2, 5, 7, 0, 0, 0, 0],\n",
       " [2, 5, 3, 0, 0, 0, 0],\n",
       " [8, 8, 4, 3, 1, 2, 1],\n",
       " [2, 1, 4, 1, 0, 0, 0]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens_enc_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f34c6",
   "metadata": {},
   "source": [
    "# 2. Vector Representation\n",
    "\n",
    "## (1) Word Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e823e477",
   "metadata": {},
   "source": [
    "### one-hot encoding\n",
    "\n",
    "- <span style = 'font-size:1.1em;line-height:1.5em'>단어 집합의 크기를 벡터 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여</span>\n",
    "- <span style = 'font-size:1.1em;line-height:1.5em'>다른 인덱스는 0을 부여하는 단어의 벡터 표현 방식</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca90e2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " 'OOV': 1,\n",
       " 'barber': 2,\n",
       " 'secret': 3,\n",
       " 'huge': 4,\n",
       " 'kept': 5,\n",
       " 'person': 6,\n",
       " 'word': 7,\n",
       " 'keeping': 8}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d20b4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = new_word_dict.copy()\n",
    "del word_dict['<PAD>']\n",
    "del word_dict['OOV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c191e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 2, 'secret': 3, 'huge': 4, 'kept': 5, 'person': 6, 'word': 7, 'keeping': 8}\n"
     ]
    }
   ],
   "source": [
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6ca5593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 0, 'secret': 1, 'huge': 2, 'kept': 3, 'person': 4, 'word': 5, 'keeping': 6}\n"
     ]
    }
   ],
   "source": [
    "for k, v in word_dict.items():\n",
    "    word_dict[k] -= 2\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28d8a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word, word_dict):\n",
    "    one_hot_vector = [0] * len(word_dict)\n",
    "    print(one_hot_vector)\n",
    "    idx = word_dict[word]\n",
    "    print(idx)\n",
    "    one_hot_vector[idx] = 1\n",
    "    print(one_hot_vector)\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b1b738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0]\n",
      "0\n",
      "[1, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding('barber', word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce9cff",
   "metadata": {},
   "source": [
    "## (2) Document Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0bb096",
   "metadata": {},
   "source": [
    "- <span style = 'font-size:1.2em;line-height:1.5em'>One-hot Encoding은 <b>단어</b>의 벡터 표현 방식이었다면, 지금 부터는 <b>문서</b>의 벡터 표현 방식</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72bd86d",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b5f5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"A barber is a person. a barber is good person. a barber is huge person. \"\n",
    "doc2 = \"he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. \"\n",
    "doc3 = \"a barber kept his word. His barber kept his secret. \"\n",
    "doc4 = \"But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain. \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62cb8eb",
   "metadata": {},
   "source": [
    "- <span style = 'font-size:1.2em;line-height:1.5em'>OOV와 stopword removal없이 일단 모든 단어의 단어 사전을 다시 만들어 볼게요.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31926790",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = [doc1, doc2, doc3, doc4]\n",
    "all_tokens = []\n",
    "for doc in all_docs:\n",
    "    doc_tokens = []\n",
    "    sentences = sent_tokenize(doc)\n",
    "    for sent in sentences:\n",
    "        sent_tokens = []\n",
    "        sent = sent.lower()\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            if (word not in stopwords_eng) & (len(word) > 2):\n",
    "                sent_tokens.append(word)\n",
    "        doc_tokens.append(sent_tokens)\n",
    "    all_tokens.append(doc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7fe55b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['barber', 'person'],\n",
       "  ['barber', 'good', 'person'],\n",
       "  ['barber', 'huge', 'person']],\n",
       " [['knew', 'secret'],\n",
       "  ['secret', 'kept', 'huge', 'secret'],\n",
       "  ['huge', 'secret'],\n",
       "  ['barber', 'kept', 'word']],\n",
       " [['barber', 'kept', 'word'], ['barber', 'kept', 'secret']],\n",
       " [['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
       "  ['barber', 'went', 'huge', 'mountain']]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd5fe9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "for doc_tokens in all_tokens:\n",
    "    for sent_tokens in doc_tokens:\n",
    "        all_words.extend(sent_tokens)\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40bd0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0b4df3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'barber': 8,\n",
       "         'person': 3,\n",
       "         'good': 1,\n",
       "         'huge': 5,\n",
       "         'knew': 1,\n",
       "         'secret': 6,\n",
       "         'kept': 4,\n",
       "         'word': 2,\n",
       "         'keeping': 2,\n",
       "         'driving': 1,\n",
       "         'crazy': 1,\n",
       "         'went': 1,\n",
       "         'mountain': 1})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "469cb430",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = {k:v for k, v in sorted(cnt.items(), key = lambda x: x[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3282a7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barber': 8,\n",
       " 'secret': 6,\n",
       " 'huge': 5,\n",
       " 'kept': 4,\n",
       " 'person': 3,\n",
       " 'word': 2,\n",
       " 'keeping': 2,\n",
       " 'good': 1,\n",
       " 'knew': 1,\n",
       " 'driving': 1,\n",
       " 'crazy': 1,\n",
       " 'went': 1,\n",
       " 'mountain': 1}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4847ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 0, 'secret': 1, 'huge': 2, 'kept': 3, 'person': 4, 'word': 5, 'keeping': 6, 'good': 7, 'knew': 8, 'driving': 9, 'crazy': 10, 'went': 11, 'mountain': 12}\n"
     ]
    }
   ],
   "source": [
    "# {단어: index}형태의 dictionary 만들기\n",
    "word_dict = dict()\n",
    "for i, word in enumerate(cnt):\n",
    "    word_dict[word] = i\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba7912b",
   "metadata": {},
   "source": [
    "- <span style = 'font-size:1.2em;line-height:1.5em'>doc1에 대한 BoW를 나타내면 다음과 같습니다</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d24bf310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A barber is a person. a barber is good person. a barber is huge person. \n"
     ]
    }
   ],
   "source": [
    "print(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66b51d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_bow(documents, word_dict):\n",
    "    bow = [0]*len(word_dict)\n",
    "    doc_words = []\n",
    "    for sent in documents:\n",
    "        doc_words.extend(sent)\n",
    "    cnt = Counter(doc_words)\n",
    "    for word, word_cnt in cnt.items():\n",
    "        idx = word_dict[word]\n",
    "        bow[idx] = word_cnt\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acac11a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['barber', 'person'],\n",
       "  ['barber', 'good', 'person'],\n",
       "  ['barber', 'huge', 'person']],\n",
       " [['knew', 'secret'],\n",
       "  ['secret', 'kept', 'huge', 'secret'],\n",
       "  ['huge', 'secret'],\n",
       "  ['barber', 'kept', 'word']],\n",
       " [['barber', 'kept', 'word'], ['barber', 'kept', 'secret']],\n",
       " [['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
       "  ['barber', 'went', 'huge', 'mountain']]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1dfe8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 1, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_to_bow(all_tokens[0], word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e92715e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['barber', 'person'],\n",
       " ['barber', 'good', 'person'],\n",
       " ['barber', 'huge', 'person']]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63f3c265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barber': 0,\n",
       " 'secret': 1,\n",
       " 'huge': 2,\n",
       " 'kept': 3,\n",
       " 'person': 4,\n",
       " 'word': 5,\n",
       " 'keeping': 6,\n",
       " 'good': 7,\n",
       " 'knew': 8,\n",
       " 'driving': 9,\n",
       " 'crazy': 10,\n",
       " 'went': 11,\n",
       " 'mountain': 12}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db80cdb",
   "metadata": {},
   "source": [
    "- <span style = 'font-size:1.2em;line-height:1.5em'>Scikit-learn의 CountVectorizer를 사용하면 쉽게 BoW를 만들 수도 있습니다.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b45d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [doc1, doc2, doc3, doc4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f5006f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A barber is a person. a barber is good person. a barber is huge person. ',\n",
       " 'he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. ',\n",
       " 'a barber kept his word. His barber kept his secret. ',\n",
       " 'But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain. ']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6e51dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[3 0 1 0 3 0 0 1 0 0 0 0 0]]\n",
      "vocabulary : {'barber': 0, 'secret': 1, 'huge': 2, 'kept': 3, 'person': 4, 'word': 5, 'keeping': 6, 'good': 7, 'knew': 8, 'driving': 9, 'crazy': 10, 'went': 11, 'mountain': 12}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vector = CountVectorizer(vocabulary = word_dict)\n",
    "\n",
    "print('bag of words vector :', vector.fit_transform([doc1]).toarray())\n",
    "\n",
    "print('vocabulary :',vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dad7ea",
   "metadata": {},
   "source": [
    "- <span style = 'font-size:1.2em;line-height:1.5em'>그러나, 이렇게 접근하면 text를 전처리 한 결과를 BoW로 만들 수 없습니다.</span>\n",
    "- <span style = 'font-size:1.2em;line-height:1.5em'>그러기 위해서는 전처리 한 후의 결과를 ' '.join(corpus)로 token들은 문장형태로 join한 뒤에 사용해야 합니다.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c21547b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.transform([doc1]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aabe2b",
   "metadata": {},
   "source": [
    "### DTM (Document Term Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96adb46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04102ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [doc1, doc2, doc3, doc4]\n",
    "vector = CountVectorizer(vocabulary=word_dict)\n",
    "results = vector.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d3bcbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 4, 2, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [2, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [2, 1, 2, 0, 0, 0, 2, 0, 0, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a075649",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3581a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4fdf8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [doc1, doc2, doc3, doc4]\n",
    "vector = CountVectorizer(vocabulary=word_dict)\n",
    "dtm = vector.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6ab657db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A barber is a person. a barber is good person. a barber is huge person. ',\n",
       " 'he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. ',\n",
       " 'a barber kept his word. His barber kept his secret. ',\n",
       " 'But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain. ']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5264bd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer(vocabulary=word_dict)\n",
    "tfidf = vector.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7217010a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 0, 1, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 4, 2, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [2, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [2, 1, 2, 0, 0, 0, 2, 0, 0, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c3c005e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43658465, 0.        , 0.1780019 , 0.        , 0.83662312,\n",
       "        0.        , 0.        , 0.27887437, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.14743115, 0.72131784, 0.36065892, 0.44548552, 0.        ,\n",
       "        0.22274276, 0.        , 0.        , 0.28252095, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.48637404, 0.29745263, 0.        , 0.73482636, 0.        ,\n",
       "        0.36741318, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.31289074, 0.19135514, 0.38271029, 0.        , 0.        ,\n",
       "        0.        , 0.59958962, 0.        , 0.        , 0.29979481,\n",
       "        0.29979481, 0.29979481, 0.29979481]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca814a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtm.shape)\n",
    "print(tfidf.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
